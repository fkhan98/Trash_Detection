{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aquatrash_yolov3",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxKk4sNuScKd"
      },
      "source": [
        "# Trash detection using YOLOv3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saMEozkBjPoL"
      },
      "source": [
        "## Setup \n",
        "We have configure the YOLOV3 Ultralytics repository to train the traffic dataset. In this example we are going to use 30% of the dataset for training and testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGHmVaYA8U1_",
        "outputId": "5680eeea-aee6-4769-c1b2-2585d112d195"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 5527717568980457162, name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 7306523456\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 11531474542644728465\n",
              " physical_device_desc: \"device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgpwmMm_bM-p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a34ddbf-7451-44fd-ae27-62b52361ad01"
      },
      "source": [
        "!git clone https://github.com/rifat963/yolov3-wrapper-for-custom-data.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'yolov3-wrapper-for-custom-data'...\n",
            "remote: Enumerating objects: 107, done.\u001b[K\n",
            "remote: Counting objects: 100% (107/107), done.\u001b[K\n",
            "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
            "remote: Total 107 (delta 38), reused 91 (delta 24), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (107/107), 871.67 KiB | 7.45 MiB/s, done.\n",
            "Resolving deltas: 100% (38/38), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wD05A7wbRTH"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "%cd /content/yolov3-wrapper-for-custom-data/data\n",
        "!gdown --id 1AJF_bgKo3suxBoCxbA9ijXkwmGN-l8QT\n",
        "!unzip trash-processed.zip; rm trash-processed.zip;\n",
        "clear_output()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuGFslpT6obt"
      },
      "source": [
        "%cp '/content/yolov3-wrapper-for-custom-data/data/metadata/train.txt' /content/yolov3-wrapper-for-custom-data/\n",
        "%cp '/content/yolov3-wrapper-for-custom-data/data/metadata/valid.txt' /content/yolov3-wrapper-for-custom-data/\n",
        "%cp '/content/yolov3-wrapper-for-custom-data/data/metadata/test.txt' /content/yolov3-wrapper-for-custom-data/\n",
        "%cp '/content/yolov3-wrapper-for-custom-data/data/metadata/trash.names' /content/yolov3-wrapper-for-custom-data/\n",
        "%cp '/content/yolov3-wrapper-for-custom-data/data/metadata/trash.data' /content/yolov3-wrapper-for-custom-data/"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqrVIu1TzpaR"
      },
      "source": [
        "Downloading pretrained weights\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcUccUb3sOdo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92a74962-d5de-490c-c3e7-579c49541c02"
      },
      "source": [
        "%cd /content/yolov3-wrapper-for-custom-data/weights/\n",
        "!gdown --id 1UcR-zVoMs7DH5dj3N1bswkiQTA4dmKF4"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/yolov3-wrapper-for-custom-data/weights\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1UcR-zVoMs7DH5dj3N1bswkiQTA4dmKF4\n",
            "To: /content/yolov3-wrapper-for-custom-data/weights/yolov3-spp-ultralytics.pt\n",
            "252MB [00:01, 145MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OWz0rnPzoue"
      },
      "source": [
        "Downlaoding cfg file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIsFLqKmzc33",
        "outputId": "d24a787b-e20f-4392-c72f-8e271c628415"
      },
      "source": [
        "%cd /content/yolov3-wrapper-for-custom-data/cfg/\n",
        "\n",
        "!gdown --id 1VNiWirrI66f6_A7Vd_CMZCBjC2eIKLY4"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/yolov3-wrapper-for-custom-data/cfg\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1VNiWirrI66f6_A7Vd_CMZCBjC2eIKLY4\n",
            "To: /content/yolov3-wrapper-for-custom-data/cfg/yolov3-spp-4cls.cfg\n",
            "100% 8.59k/8.59k [00:00<00:00, 15.5MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96f5Zbz7uluy"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFWsn8M3ukdS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d57a87e4-645f-44ca-9b89-4fa4e0f0cb93"
      },
      "source": [
        "%cd /content/yolov3-wrapper-for-custom-data\n",
        "\n",
        "!python train.py --cfg cfg/yolov3-spp-4cls.cfg \\\n",
        "                 --data trash.data \\\n",
        "                 --epochs 80 \\\n",
        "                 --batch-size  6 \\\n",
        "                 --weights weights/yolov3-spp-ultralytics.pt \\\n",
        "                 --name yolov3-trash "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/yolov3-wrapper-for-custom-data\n",
            "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
            "Namespace(adam=False, batch_size=6, bucket='', cache_images=False, cfg='cfg/yolov3-spp-4cls.cfg', data='trash.data', device='', epochs=80, evolve=False, freeze_layers=False, img_size=[320, 640], multi_scale=False, name='yolov3-trash', nosave=False, notest=False, rect=False, resume=False, single_cls=False, weights='weights/yolov3-spp-ultralytics.pt')\n",
            "Using CUDA device0 _CudaDeviceProperties(name='Tesla P4', total_memory=7611MB)\n",
            "\n",
            "Start Tensorboard with \"tensorboard --logdir=runs\", view at http://localhost:6006/\n",
            "2021-04-17 17:22:03.381371: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "WARNING: smart bias initialization failure.\n",
            "WARNING: smart bias initialization failure.\n",
            "WARNING: smart bias initialization failure.\n",
            "Model Summary: 225 layers, 6.25895e+07 parameters, 6.25895e+07 gradients\n",
            "Optimizer groups: 76 .bias, 76 Conv2d.weight, 73 other\n",
            "Caching labels train.txt (300 found, 0 missing, 0 empty, 0 duplicate, for 300 images): 100% 300/300 [00:00<00:00, 8813.78it/s]\n",
            "Caching labels valid.txt (69 found, 0 missing, 0 empty, 0 duplicate, for 69 images): 100% 69/69 [00:00<00:00, 8392.26it/s]\n",
            "Image sizes 320 - 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Starting training for 80 epochs...\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "  0% 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/cuda/memory.py:375: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
            "  FutureWarning)\n",
            "      0/79     6.91G      7.21      15.3      3.82      26.4         8       544: 100% 50/50 [00:58<00:00,  1.17s/it]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:14<00:00,  1.19s/it]\n",
            "                 all        69       100         0         0    0.0064         0\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "      1/79     6.87G      5.14      2.01      3.26      10.4        14       384: 100% 50/50 [00:28<00:00,  1.78it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:05<00:00,  2.40it/s]\n",
            "                 all        69       100         0         0     0.078         0\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "      2/79     6.88G      4.28      1.49      2.96      8.73        10       576: 100% 50/50 [00:28<00:00,  1.76it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:05<00:00,  2.06it/s]\n",
            "                 all        69       100   0.00247    0.0637   0.00249   0.00475\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "      3/79     6.89G      3.93      1.07      2.89      7.89        11       608: 100% 50/50 [00:33<00:00,  1.49it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:04<00:00,  2.58it/s]\n",
            "                 all        69       100    0.0102    0.0511   0.00821    0.0169\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "      4/79     6.89G       3.8      1.14      2.85      7.79        12       544: 100% 50/50 [00:27<00:00,  1.80it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:04<00:00,  2.73it/s]\n",
            "                 all        69       100      0.34    0.0952    0.0628     0.107\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "      5/79     6.89G      3.77      1.26      2.88      7.91         9       576: 100% 50/50 [00:25<00:00,  1.95it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:04<00:00,  2.84it/s]\n",
            "                 all        69       100    0.0431     0.102    0.0363    0.0607\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "      6/79     6.89G      3.83     0.888      2.85      7.57        13       416: 100% 50/50 [00:31<00:00,  1.60it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:04<00:00,  2.59it/s]\n",
            "                 all        69       100     0.285    0.0384    0.0413    0.0506\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "      7/79     6.89G       3.7     0.835      2.83      7.36        11       544: 100% 50/50 [00:34<00:00,  1.44it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:04<00:00,  2.50it/s]\n",
            "                 all        69       100    0.0166    0.0162    0.0116    0.0164\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "      8/79     6.89G      3.83     0.933      2.88      7.64        17       352: 100% 50/50 [00:33<00:00,  1.49it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:04<00:00,  2.48it/s]\n",
            "                 all        69       100      0.29    0.0275    0.0723    0.0484\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "      9/79     6.89G      3.44     0.798      2.81      7.04        10       640: 100% 50/50 [00:33<00:00,  1.50it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:04<00:00,  2.43it/s]\n",
            "                 all        69       100      0.34    0.0476    0.0814     0.075\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "     10/79     6.89G       3.7      1.01      2.89       7.6        12       320: 100% 50/50 [00:24<00:00,  2.02it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:06<00:00,  1.93it/s]\n",
            "                 all        69       100     0.218     0.208     0.179     0.211\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "     11/79      6.9G      3.32     0.992      2.81      7.12        14       384: 100% 50/50 [00:23<00:00,  2.15it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:04<00:00,  2.47it/s]\n",
            "                 all        69       100     0.189     0.179     0.142     0.183\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "     12/79      6.9G       3.2     0.857       2.8      6.86        11       384: 100% 50/50 [00:23<00:00,  2.16it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:04<00:00,  2.48it/s]\n",
            "                 all        69       100     0.128     0.159    0.0994     0.139\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "     13/79      6.9G      3.15     0.948      2.77      6.86        13       640: 100% 50/50 [00:29<00:00,  1.71it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:04<00:00,  2.88it/s]\n",
            "                 all        69       100     0.172      0.16     0.117     0.165\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "     14/79      6.9G      3.09     0.773      2.67      6.53        11       320: 100% 50/50 [00:35<00:00,  1.41it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:04<00:00,  2.91it/s]\n",
            "                 all        69       100     0.195     0.268     0.174     0.225\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "     15/79      6.9G      3.01      0.81      2.66      6.48        13       608: 100% 50/50 [00:29<00:00,  1.69it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:04<00:00,  2.93it/s]\n",
            "                 all        69       100     0.154      0.16     0.152     0.155\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "     16/79      6.9G      2.81     0.858      2.66      6.33         9       480: 100% 50/50 [00:27<00:00,  1.80it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:04<00:00,  2.90it/s]\n",
            "                 all        69       100     0.135     0.349     0.151     0.194\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "     17/79      6.9G      2.99     0.927      2.63      6.55         9       320: 100% 50/50 [00:24<00:00,  2.03it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:04<00:00,  2.63it/s]\n",
            "                 all        69       100     0.116     0.313      0.13     0.162\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "     18/79      6.9G      2.92     0.878      2.72      6.52        10       416: 100% 50/50 [00:24<00:00,  2.02it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:04<00:00,  2.95it/s]\n",
            "                 all        69       100     0.177     0.293      0.19      0.22\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "     19/79      6.9G      2.84     0.829       2.6      6.27        14       576: 100% 50/50 [00:29<00:00,  1.72it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:04<00:00,  2.99it/s]\n",
            "                 all        69       100     0.109     0.229     0.138     0.141\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "     20/79      6.9G      2.74     0.789      2.63      6.17        13       352: 100% 50/50 [00:27<00:00,  1.81it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:03<00:00,  3.04it/s]\n",
            "                 all        69       100     0.132     0.265     0.146     0.171\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "     21/79      6.9G      2.74     0.743      2.53      6.02         8       448: 100% 50/50 [00:26<00:00,  1.87it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:03<00:00,  3.03it/s]\n",
            "                 all        69       100     0.145     0.271     0.139     0.187\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "     22/79      6.9G      2.63     0.836      2.49      5.95         8       576: 100% 50/50 [00:25<00:00,  1.99it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:04<00:00,  2.91it/s]\n",
            "                 all        69       100     0.112     0.263     0.103      0.15\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "     23/79      6.9G      2.73     0.798       2.6      6.13        10       512: 100% 50/50 [00:29<00:00,  1.71it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:04<00:00,  2.72it/s]\n",
            "                 all        69       100     0.186     0.298     0.136     0.205\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "     24/79      6.9G      2.57     0.719      2.54      5.83         9       544: 100% 50/50 [00:26<00:00,  1.87it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:04<00:00,  2.89it/s]\n",
            "                 all        69       100     0.169      0.31     0.185     0.216\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "     25/79      6.9G      2.57     0.683      2.57      5.82        11       320: 100% 50/50 [00:31<00:00,  1.58it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:03<00:00,  3.03it/s]\n",
            "                 all        69       100     0.161     0.272     0.151     0.202\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "     26/79      6.9G      2.65     0.791       2.4      5.84        10       480: 100% 50/50 [00:26<00:00,  1.90it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:03<00:00,  3.03it/s]\n",
            "                 all        69       100     0.385     0.292     0.201     0.236\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "     27/79      6.9G       2.4     0.665      2.48      5.55        14       544: 100% 50/50 [00:31<00:00,  1.61it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:04<00:00,  2.98it/s]\n",
            "                 all        69       100     0.165     0.264     0.181     0.201\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "     28/79      6.9G      2.45     0.687      2.42      5.56        10       544: 100% 50/50 [00:30<00:00,  1.64it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:04<00:00,  3.00it/s]\n",
            "                 all        69       100     0.232     0.315     0.222      0.24\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "     29/79      6.9G      2.35       0.5      2.21      5.06         9       448: 100% 50/50 [00:37<00:00,  1.35it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:03<00:00,  3.01it/s]\n",
            "                 all        69       100     0.218     0.341     0.249     0.261\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "     30/79      6.9G      2.38     0.557      2.13      5.07         9       640: 100% 50/50 [00:34<00:00,  1.47it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:04<00:00,  2.99it/s]\n",
            "                 all        69       100     0.232     0.409     0.271     0.292\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "     31/79      6.9G      2.53      0.69      2.24      5.46        12       544: 100% 50/50 [00:26<00:00,  1.88it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:04<00:00,  2.88it/s]\n",
            "                 all        69       100     0.219     0.325     0.206     0.238\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "     32/79      6.9G      2.59     0.744      2.24      5.57        11       576: 100% 50/50 [00:26<00:00,  1.88it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:03<00:00,  3.00it/s]\n",
            "                 all        69       100     0.137     0.313     0.148     0.187\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "     33/79      6.9G       2.2     0.654      2.08      4.93         8       480: 100% 50/50 [00:26<00:00,  1.92it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:04<00:00,  2.94it/s]\n",
            "                 all        69       100     0.215      0.35     0.208     0.258\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "     34/79      6.9G      2.35      0.52      1.96      4.83        13       608: 100% 50/50 [00:33<00:00,  1.49it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:04<00:00,  2.97it/s]\n",
            "                 all        69       100     0.224     0.302     0.226     0.253\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "     35/79      6.9G      2.37     0.569      1.99      4.93         8       448: 100% 50/50 [00:35<00:00,  1.42it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 12/12 [00:04<00:00,  2.99it/s]\n",
            "                 all        69       100     0.259     0.325     0.241     0.236\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "     36/79      6.9G      2.49     0.493      2.04      5.03         9       512:  32% 16/50 [00:09<00:19,  1.76it/s]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oz9KVqdzF860",
        "outputId": "ae55ae95-b962-4248-859a-bb5bcca6141f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igQuKVf8FuvF",
        "outputId": "189b82b6-175e-42cb-a028-73a96893c465"
      },
      "source": [
        "%cd /content/yolov3-wrapper-for-custom-data/weights\n",
        "!cp best_yolov3-trash.pt '/content/drive/MyDrive/Plastic Detection'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/yolov3-wrapper-for-custom-data/weights\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgFKBkPzFxKe"
      },
      "source": [
        "# Test Submissions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FpG3hqFFwlG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1afe8e4-625e-43a1-fbb5-be2b272603ea"
      },
      "source": [
        "!python test.py --data trash.data --cfg cfg/yolov3-spp-4cls.cfg --weights weights/best_yolov3-trash.pt --img 400 --augment"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(augment=True, batch_size=16, cfg='cfg/yolov3-spp-4cls.cfg', conf_thres=0.001, data='trash.data', device='', img_size=400, iou_thres=0.6, save_json=False, single_cls=False, task='test', weights='weights/best_yolov3-trash.pt')\n",
            "Using CUDA device0 _CudaDeviceProperties(name='Tesla T4', total_memory=15109MB)\n",
            "\n",
            "WARNING: smart bias initialization failure.\n",
            "WARNING: smart bias initialization failure.\n",
            "WARNING: smart bias initialization failure.\n",
            "Model Summary: 225 layers, 6.25895e+07 parameters, 6.25895e+07 gradients\n",
            "Fusing layers...\n",
            "Model Summary: 152 layers, 6.25627e+07 parameters, 6.25627e+07 gradients\n",
            "Caching labels valid.txt (69 found, 0 missing, 0 empty, 0 duplicate, for 69 images): 100% 69/69 [00:00<00:00, 1897.27it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"test.py\", line 263, in <module>\n",
            "    opt.augment)\n",
            "  File \"test.py\", line 76, in test\n",
            "    _ = model(torch.zeros((1, 3, imgsz, imgsz), device=device)) if device.type != 'cpu' else None  # run once\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/yolov3-wrapper-for-custom-data/models.py\", line 244, in forward\n",
            "    return self.forward_once(x)\n",
            "  File \"/content/yolov3-wrapper-for-custom-data/models.py\", line 294, in forward_once\n",
            "    x = module(x, out)  # WeightedFeatureFusion(), FeatureConcat()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/yolov3-wrapper-for-custom-data/utils/layers.py\", line 35, in forward\n",
            "    return torch.cat([outputs[i] for i in self.layers], 1) if self.multiple else outputs[self.layers[0]]\n",
            "RuntimeError: Sizes of tensors must match except in dimension 2. Got 25 and 26 (The offending index is 0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "komO8CbeyJwy"
      },
      "source": [
        "# Sample example to create submission file\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAHNsHXKvbSN"
      },
      "source": [
        "from models import *  \n",
        "from utils.datasets import *\n",
        "from utils.utils import *\n",
        "\n",
        "def detect(save_img=False):\n",
        "    imgsz = opt.img_size \n",
        "    out, source, weights, half, view_img, save_txt = opt.output, opt.source, opt.weights, opt.half, opt.view_img, opt.save_txt\n",
        "\n",
        "    # Initialize\n",
        "    device = torch_utils.select_device(opt.device)\n",
        "    if os.path.exists(out):\n",
        "        shutil.rmtree(out)  # delete output folder\n",
        "    os.makedirs(out)  # make new output folder\n",
        "\n",
        "    # Initialize model\n",
        "    model = Darknet(opt.cfg, imgsz)\n",
        "\n",
        "    # Load weights\n",
        "    attempt_download(weights)\n",
        "    if weights.endswith('.pt'):  # pytorch format\n",
        "        model.load_state_dict(torch.load(weights, map_location=device)['model'])\n",
        "    else:  # darknet format\n",
        "        load_darknet_weights(model, weights)\n",
        "\n",
        "    \n",
        "    # Eval mode\n",
        "    model.to(device).eval()\n",
        "\n",
        "    # Half precision\n",
        "    half = half and device.type != 'cpu'  # half precision only supported on CUDA\n",
        "    if half:\n",
        "        model.half()\n",
        "\n",
        "    # Set Dataloader\n",
        "    vid_path, vid_writer = None, None\n",
        "    save_img = True\n",
        "    dataset = LoadImages(source, img_size=imgsz)\n",
        "\n",
        "    # Get names and colors\n",
        "    names = load_classes(opt.names)\n",
        "    colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(names))]\n",
        "\n",
        "    # Run inference\n",
        "    t0 = time.time()\n",
        "    img = torch.zeros((1, 3, imgsz, imgsz), device=device)  # init img\n",
        "    _ = model(img.half() if half else img.float()) if device.type != 'cpu' else None  # run once\n",
        "\n",
        "    results=[]\n",
        "    for path, img, im0s, vid_cap in dataset:\n",
        "        img = torch.from_numpy(img).to(device)\n",
        "        img = img.half() if half else img.float()  # uint8 to fp16/32\n",
        "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
        "        if img.ndimension() == 3:\n",
        "            img = img.unsqueeze(0)\n",
        "\n",
        "        # Inference\n",
        "        t1 = torch_utils.time_synchronized()\n",
        "        pred = model(img, augment=opt.augment)[0]\n",
        "        t2 = torch_utils.time_synchronized()\n",
        "\n",
        "        # to float\n",
        "        if half:\n",
        "            pred = pred.float()\n",
        "\n",
        "        # Apply NMS\n",
        "        pred = non_max_suppression(pred, opt.conf_thres, opt.iou_thres,\n",
        "                                   multi_label=False, classes=opt.classes, agnostic=opt.agnostic_nms)\n",
        "\n",
        "        \n",
        "        # Process detections\n",
        "        for i, det in enumerate(pred):  # detections for image i\n",
        "            \n",
        "            p, s, im0 = path, '', im0s          \n",
        "\n",
        "            save_path = str(Path(out) / Path(p).name)\n",
        "            #print(p)\n",
        "            s += '%gx%g ' % img.shape[2:]  # print string\n",
        "            #print(s)\n",
        "            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  #  normalization gain whwh\n",
        "            if det is not None and len(det):\n",
        "                # Rescale boxes from imgsz to im0 size\n",
        "                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
        "\n",
        "                # Print results\n",
        "                for c in det[:, -1].unique():\n",
        "                    n = (det[:, -1] == c).sum()  # detections per class\n",
        "                    s += '%g %ss, ' % (n, names[int(c)])  # add to string\n",
        "\n",
        "                xmin = []\n",
        "                ymin = []\n",
        "                xmax = []\n",
        "                ymax = []\n",
        "                scores = []\n",
        "                labels_value=[]\n",
        "                image_ids=[]\n",
        "                # Write results\n",
        "                for *xyxy, conf, cls in det:\n",
        "                    if save_txt:  # Write to file\n",
        "                        \n",
        "                        conf_score = '%.2f' % (conf)\n",
        "                        label_with_cls = '%s' % (names[int(cls)])\n",
        "                        \n",
        "                        labels_value.append(label_with_cls)\n",
        "                        \n",
        "                        xmin.append(int(xyxy[0]))\n",
        "                        ymin.append(int(xyxy[1]))\n",
        "                        xmax.append(int(xyxy[2]))\n",
        "                        ymax.append(int(xyxy[3]))\n",
        "                        \n",
        "                        scores.append(conf_score)\n",
        "                        image_ids.append(save_path)\n",
        "\n",
        "                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
        "                        with open(save_path[:save_path.rfind('.')] + '.txt', 'a') as file:\n",
        "                            file.write(('%g ' * 5 + '\\n') % (cls, *xywh))  # label format\n",
        "\n",
        "                    if save_img or view_img:  # Add bbox to image\n",
        "                        label = '%s %.2f' % (names[int(cls)], conf)\n",
        "                        plot_one_box(xyxy, im0, label=label, color=colors[int(cls)])\n",
        "\n",
        "            # Print time (inference + NMS)\n",
        "            print('%sDone. (%.3fs)' % (s, t2 - t1))\n",
        "\n",
        "            # Stream results\n",
        "            if view_img:\n",
        "                cv2.imshow(p, im0)\n",
        "                if cv2.waitKey(1) == ord('q'):  # q to quit\n",
        "                    raise StopIteration\n",
        "\n",
        "            # Save results (image with detections)\n",
        "            if save_img:\n",
        "                if dataset.mode == 'images':\n",
        "                    cv2.imwrite(save_path, im0)\n",
        "        result = {\n",
        "            'image_id': image_ids,\n",
        "            'score': scores,\n",
        "            'class': labels_value,\n",
        "            'xmin': xmin,\n",
        "            'ymin': ymin,\n",
        "            'xmax': xmax,\n",
        "            'ymax': ymax\n",
        "\n",
        "            }\n",
        "\n",
        "        results.append(result)\n",
        "\n",
        "    if save_txt or save_img:\n",
        "        print('Results saved to %s' % os.getcwd() + os.sep + out)\n",
        "\n",
        "    print('Done. (%.3fs)' % (time.time() - t0))\n",
        "    return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwFzjW7Nyrsu"
      },
      "source": [
        "class opt:\n",
        "    cfg='/content/yolov3-wrapper-for-custom-data/cfg/yolov3-spp-23cls.cfg'\n",
        "    names='traffic.names'\n",
        "    weights='weights/best_yolov3-traffic.pt'\n",
        "    source='data/test'\n",
        "    save_txt=True\n",
        "    output='output'\n",
        "    classes=False\n",
        "    img_size=1024\n",
        "    conf_thres=0.3\n",
        "    iou_thres=0.6\n",
        "    fourcc='mp4v'\n",
        "    half=False\n",
        "    device=''\n",
        "    view_img=False\n",
        "    agnostic_nms=False\n",
        "    augment=False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdQNj5GCyuyw"
      },
      "source": [
        "# predict results\n",
        "with torch.no_grad():\n",
        "    res=detect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSaSc4fdak1q"
      },
      "source": [
        "### Submission file structure\n",
        "\n",
        "In the submission file you need to have to following headers with values\n",
        "\n",
        "\n",
        "\n",
        "*   image_id\n",
        "*   class\n",
        "*   score\n",
        "*   xmin\n",
        "*   ymin\n",
        "*   xmax\n",
        "*   ymax\n",
        "*   height\n",
        "*   width\n",
        "\n",
        "**Remember all the test images are rescaled into 1024x1024 so the bounding boxes must be scaled for 1024x1024 image size**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbZgmn7Ly6D5"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "append_data=[]\n",
        "\n",
        "for i in range(len(res)):\n",
        "  \n",
        "  df = pd.DataFrame(res[i], columns = ['image_id','class','score','xmin','ymin','xmax','ymax'])\n",
        " \n",
        "  append_data.append(df)\n",
        "\n",
        "finl_results=pd.concat(append_data)\n",
        "\n",
        "finl_results.image_id = [x.strip('output/') for x in finl_results.image_id]\n",
        "\n",
        "finl_results['width'] = 1024\n",
        "finl_results['height'] = 1024\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2S_UJi7V02Fs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "b245a787-151f-4adf-b3d9-26a35efd9708"
      },
      "source": [
        "finl_results.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>class</th>\n",
              "      <th>score</th>\n",
              "      <th>xmin</th>\n",
              "      <th>ymin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymax</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Numan_(101)_jpg.rf.a9abd780ae62e7aa8a861c7693d...</td>\n",
              "      <td>rickshaw</td>\n",
              "      <td>0.79</td>\n",
              "      <td>766</td>\n",
              "      <td>230</td>\n",
              "      <td>904</td>\n",
              "      <td>552</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Numan_(133)_jpg.rf.1e1ec524e09e67f50afdc03fd3a...</td>\n",
              "      <td>rickshaw</td>\n",
              "      <td>0.93</td>\n",
              "      <td>535</td>\n",
              "      <td>110</td>\n",
              "      <td>648</td>\n",
              "      <td>435</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Numan_(133)_jpg.rf.1e1ec524e09e67f50afdc03fd3a...</td>\n",
              "      <td>bus</td>\n",
              "      <td>0.73</td>\n",
              "      <td>467</td>\n",
              "      <td>28</td>\n",
              "      <td>594</td>\n",
              "      <td>200</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Numan_(133)_jpg.rf.1e1ec524e09e67f50afdc03fd3a...</td>\n",
              "      <td>pickup</td>\n",
              "      <td>0.50</td>\n",
              "      <td>647</td>\n",
              "      <td>99</td>\n",
              "      <td>723</td>\n",
              "      <td>205</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Numan_(133)_jpg.rf.1e1ec524e09e67f50afdc03fd3a...</td>\n",
              "      <td>rickshaw</td>\n",
              "      <td>0.93</td>\n",
              "      <td>535</td>\n",
              "      <td>110</td>\n",
              "      <td>648</td>\n",
              "      <td>435</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            image_id     class  ... width  height\n",
              "0  Numan_(101)_jpg.rf.a9abd780ae62e7aa8a861c7693d...  rickshaw  ...  1024    1024\n",
              "0  Numan_(133)_jpg.rf.1e1ec524e09e67f50afdc03fd3a...  rickshaw  ...  1024    1024\n",
              "1  Numan_(133)_jpg.rf.1e1ec524e09e67f50afdc03fd3a...       bus  ...  1024    1024\n",
              "2  Numan_(133)_jpg.rf.1e1ec524e09e67f50afdc03fd3a...    pickup  ...  1024    1024\n",
              "0  Numan_(133)_jpg.rf.1e1ec524e09e67f50afdc03fd3a...  rickshaw  ...  1024    1024\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrEpXZcB02j9"
      },
      "source": [
        "finl_results.to_csv('submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}