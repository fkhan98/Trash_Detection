{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_preprocessing_trash.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlAvGKtcLbm1"
      },
      "source": [
        "# Data preprocessing License Plate Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpxEAdmRLgJp"
      },
      "source": [
        "Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybNxgJejiQOZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b689ddc9-d520-4b6b-ece2-24447a40c15a"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "import os, glob\n",
        "\n",
        "\n",
        "# Downloading teh dataset\n",
        "!gdown --id '1DJcNLTpUBc8NRgH-ZDIZ_LWSUTNzJToE'\n",
        "!unzip trash_data.zip; rm trash_data.zip;\n",
        "clear_output()\n",
        "\n",
        "# Removing unnecessary demo data folder from workspace.\n",
        "!rm -r sample_data\n",
        "\n",
        "# Renaming raw data folder to remove space. Trust me, it makes life a lot easier :D \n",
        "%mv 'train' train_data_raw\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'sample_data': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUDBDmwNQFsX"
      },
      "source": [
        "Function for converting XML to TXT\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBpK1omZjYXF",
        "outputId": "7eae4a8a-bd15-4b4b-d8e6-b8e781e4b528"
      },
      "source": [
        "from xml.dom import minidom\n",
        "\n",
        "lut={\"glass\":0,\n",
        "     \"metal\":1,\n",
        "     \"plastic\":2,\n",
        "     \"paper\":3\n",
        "     }\n",
        "\n",
        "label_count ={}\n",
        "\n",
        "print(f'Object Names: {list(lut.keys())}' ) ##using .keys() we get all the keys of dictionery\n",
        "\n",
        "def convert_coordinates(size, box):\n",
        "    \"\"\"\n",
        "    This function converts the coordinates. \n",
        "    box: (xmin, ymin, xmax, ymax)\n",
        "    size: (width, height)\n",
        "\n",
        "    returns a touple where (x, y, height, width) of the boundary box\n",
        "    \"\"\"\n",
        "    dw = 1.0/size[0]\n",
        "    dh = 1.0/size[1]\n",
        "    x = (box[0]+box[1])/2.0\n",
        "    y = (box[2]+box[3])/2.0\n",
        "    w = box[1]-box[0]\n",
        "    h = box[3]-box[2]\n",
        "    x = x*dw\n",
        "    w = w*dw\n",
        "    y = y*dh\n",
        "    h = h*dh\n",
        "    return (x,y,w,h)\n",
        "\n",
        "\n",
        "def convert_xml2yolo(filelist, lut ):\n",
        "    \"\"\"\n",
        "    filelist: list of .xml file paths to convert to .txt file\n",
        "    lut: a dictionary containing class_name to class_index mapping\n",
        "    \"\"\"\n",
        "    for fname in filelist:\n",
        "        xmldoc = minidom.parse(fname)\n",
        "        fname_out = (fname[:-4]+'.txt')\n",
        "\n",
        "        with open(fname_out, \"w\") as f:\n",
        "            # print(f'processing{fname}')\n",
        "\n",
        "            itemlist = xmldoc.getElementsByTagName('object')\n",
        "            size = xmldoc.getElementsByTagName('size')[0]\n",
        "            width = int((size.getElementsByTagName('width')[0]).firstChild.data)\n",
        "            height = int((size.getElementsByTagName('height')[0]).firstChild.data)\n",
        "\n",
        "            for item in itemlist:\n",
        "                # get class label\n",
        "                classid =  (item.getElementsByTagName('name')[0]).firstChild.data\n",
        "                if classid in lut:\n",
        "                    label_str = str(lut[classid])\n",
        "                else:\n",
        "                    #print(fname )\n",
        "                    label_str = \"-1\"\n",
        "                    #print (\"warning: label '%s' not in look-up table for file '%s'\", classid, fname )\n",
        "                # get bbox coordinates\n",
        "                xmin = ((item.getElementsByTagName('bndbox')[0]).getElementsByTagName('xmin')[0]).firstChild.data\n",
        "                ymin = ((item.getElementsByTagName('bndbox')[0]).getElementsByTagName('ymin')[0]).firstChild.data\n",
        "                xmax = ((item.getElementsByTagName('bndbox')[0]).getElementsByTagName('xmax')[0]).firstChild.data\n",
        "                ymax = ((item.getElementsByTagName('bndbox')[0]).getElementsByTagName('ymax')[0]).firstChild.data\n",
        "                b = (float(xmin), float(xmax), float(ymin), float(ymax))\n",
        "                bb = convert_coordinates((width,height), b)\n",
        "                #print(bb)\n",
        "                \n",
        "                if classid in lut:\n",
        "                  label_count[classid] = label_count.get(classid, 0) + 1\n",
        "                #label_count[classid] = label_count.get(classid, 0) + 1\n",
        "\n",
        "                if label_str != \"-1\":\n",
        "                  f.write(label_str + \" \" + \" \".join([(\"%.6f\" % a) for a in bb]) + '\\n')\n",
        "\n",
        "\n",
        "\n",
        "                #f.write(label_str + \" \" + \" \".join([(\"%.6f\" % a) for a in bb]) + '\\n')\n",
        "        # print (\"wrote %s\" % fname_out)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Object Names: ['glass', 'metal', 'plastic', 'paper']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pnr-KYKDlmsI",
        "outputId": "845b869d-8670-497e-94eb-d5dfcfe9a1e9"
      },
      "source": [
        "# Reading Image file paths\n",
        "formats = ['jpg', 'jpeg', 'JPG', 'png']\n",
        "image_file_list = []\n",
        "for format in formats:\n",
        "  #glob.glob is used to search for filepaths with a matching pattern and store the filepath in a list\n",
        "    image_file_list.extend(glob.glob(f'/content/train_data_raw/*.{format}'))\n",
        "\n",
        "# Reading XML label file paths\n",
        "label_file_list_xml = glob.glob('/content/train_data_raw/*.xml')\n",
        "\n",
        "print(f'Image files found: {len(image_file_list)} \\nLabel files found: { len(label_file_list_xml)}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image files found: 369 \n",
            "Label files found: 369\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUCEDiUymgYh",
        "outputId": "5dc5ca7c-109d-4ae9-f027-5f86677b437a"
      },
      "source": [
        "# Converting .xml file to .txt file\n",
        "convert_xml2yolo(label_file_list_xml, lut)\n",
        "label_file_list_txt = glob.glob('/content/train_data_raw/*.txt')\n",
        "print(f'XML --> TXT files: {len(label_file_list_txt)}')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XML --> TXT files: 369\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZFbB1cQm7j_",
        "outputId": "baab7257-3e3f-49fb-a5b9-80aa2fd63e71"
      },
      "source": [
        "label_count"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'glass': 41, 'metal': 127, 'paper': 127, 'plastic': 226}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVAY4tw-oBod",
        "outputId": "c23bbad7-dfcf-47d6-d37f-5dac3d3b0e9f"
      },
      "source": [
        "from PIL import Image\n",
        "img_sizes = {}\n",
        "\n",
        "for fname in image_file_list:\n",
        "    img = Image.open(fname)\n",
        "    img_sizes[img.size] = img_sizes.get(img.size, 0) +1 \n",
        "img_sizes"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(416, 416): 179,\n",
              " (1241, 751): 1,\n",
              " (1537, 2049): 33,\n",
              " (1925, 1408): 1,\n",
              " (2049, 1537): 12,\n",
              " (2214, 3264): 1,\n",
              " (2442, 2597): 1,\n",
              " (2448, 3264): 109,\n",
              " (3163, 2448): 1,\n",
              " (3264, 2448): 31}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lZNhYBSQLO0"
      },
      "source": [
        "Function for resizing image\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txEKPYGpxvvo"
      },
      "source": [
        "def resize_images(file_list, width = 800, height = 800, overwrite = True, save_dir = ''):\n",
        "    total_files = len(file_list)\n",
        "    idx = 1\n",
        "    for path in file_list:\n",
        "        img = Image.open(path)\n",
        "        img_resized = img.resize((width, height))\n",
        "        if overwrite:\n",
        "            img_resized.save(path)\n",
        "            filename = path.split('/')[-1] \n",
        "            print(f\"{idx}/{total_files}: {filename} {img.size}--> ({width}x{height})\")\n",
        "        else:\n",
        "            filename = path.split('/')[-1]\n",
        "            img_resized.save(save_dir + filename)\n",
        "            print(f'{filename} saved to {save_dir}')\n",
        "        idx +=1\n",
        "    clear_output()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDADQiSWx0DV"
      },
      "source": [
        "resize_images(image_file_list , overwrite= True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN0XjBU_QN9B"
      },
      "source": [
        "Split into train and validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owJ86eN3x2P_",
        "outputId": "d63f4d79-7698-4940-cd1a-3093ed3bfae3"
      },
      "source": [
        "import random\n",
        "random.seed(689)\n",
        "\n",
        "#randomply selecting the index of the files\n",
        "valid_set_index = random.sample(range(len(image_file_list)), 69) #randomly selecting 100 indexes from training set\n",
        "len(set(image_file_list)), len(set(label_file_list_txt)), len(valid_set_index)\n",
        "\n",
        "image_file_list = sorted(image_file_list)\n",
        "label_file_list_txt = sorted(label_file_list_txt)\n",
        "\n",
        "# sanity check of the image files and labels being in the same order\n",
        "print('Checking files concurrency')\n",
        "print(image_file_list[:5])\n",
        "print(label_file_list_txt[:5])\n",
        "\n",
        "# code to separate train and validation set\n",
        "valid_selected_images = []\n",
        "valid_selected_labels = []\n",
        "\n",
        "for index in valid_set_index: \n",
        "    valid_selected_images.append(image_file_list[index])\n",
        "    valid_selected_labels.append(label_file_list_txt[index])\n",
        "\n",
        "\n",
        "print('\\n\\nChecking files concurrency in validation set')\n",
        "print(valid_selected_images[:5])\n",
        "print(valid_selected_labels[:5])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking files concurrency\n",
            "['/content/train_data_raw/000000_JPG.rf.d3371cb3d63a59c5ba6730368b7905af.jpg', '/content/train_data_raw/000000_jpg.rf.beffaf3b548106ccf1da5dc629bc9504.jpg', '/content/train_data_raw/000000_jpg.rf.e662cb85f63817325956fea222d0990f.jpg', '/content/train_data_raw/000000_jpg.rf.ee75fdf06813399a8376c6ff7056423a.jpg', '/content/train_data_raw/000001_JPG.rf.ccfdd243a78a6cfa119be0349d18c0ed.jpg']\n",
            "['/content/train_data_raw/000000_JPG.rf.d3371cb3d63a59c5ba6730368b7905af.txt', '/content/train_data_raw/000000_jpg.rf.beffaf3b548106ccf1da5dc629bc9504.txt', '/content/train_data_raw/000000_jpg.rf.e662cb85f63817325956fea222d0990f.txt', '/content/train_data_raw/000000_jpg.rf.ee75fdf06813399a8376c6ff7056423a.txt', '/content/train_data_raw/000001_JPG.rf.ccfdd243a78a6cfa119be0349d18c0ed.txt']\n",
            "\n",
            "\n",
            "Checking files concurrency in validation set\n",
            "['/content/train_data_raw/000086_JPG.rf.a9c84c634a161dec85f5ca62fff0d0b7.jpg', '/content/train_data_raw/000022_JPG.rf.2142a3416365cf34993f4abb1d7d8458.jpg', '/content/train_data_raw/000047_JPG.rf.72be7e73ce0d387830038342f92e0d6d.jpg', '/content/train_data_raw/000000_JPG.rf.d3371cb3d63a59c5ba6730368b7905af.jpg', '/content/train_data_raw/000068_JPG.rf.b6d34dfe4b896d0c753385ca4c3072a3.jpg']\n",
            "['/content/train_data_raw/000086_JPG.rf.a9c84c634a161dec85f5ca62fff0d0b7.txt', '/content/train_data_raw/000022_JPG.rf.2142a3416365cf34993f4abb1d7d8458.txt', '/content/train_data_raw/000047_JPG.rf.72be7e73ce0d387830038342f92e0d6d.txt', '/content/train_data_raw/000000_JPG.rf.d3371cb3d63a59c5ba6730368b7905af.txt', '/content/train_data_raw/000068_JPG.rf.b6d34dfe4b896d0c753385ca4c3072a3.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LS4lj-zXyKbO",
        "outputId": "0fdbe7d0-e89b-42f4-8c4e-c7a5cec7b2fe"
      },
      "source": [
        "import shutil\n",
        "\n",
        "# Creating validation directory\n",
        "valid_dir = '/content/valid/'\n",
        "\n",
        "if os.path.exists(valid_dir):\n",
        "    print(f'Directory {valid_dir} already exists !')\n",
        "else: \n",
        "    os.makedirs(valid_dir)\n",
        "    print(f\"Directory {valid_dir} is created successfully!\") \n",
        "\n",
        "\n",
        "for idx in range(len(valid_selected_images)):\n",
        "    # moving image files\n",
        "    mypath = valid_selected_images[idx]\n",
        "    if os.path.exists(mypath):\n",
        "        filename = mypath.split('/')[-1]\n",
        "        shutil.move(mypath , valid_dir + filename)\n",
        "    else:\n",
        "        print(f'{mypath} not found')\n",
        "        \n",
        "    # moving label files\n",
        "    mypath = valid_selected_labels[idx]\n",
        "    if os.path.exists(mypath):\n",
        "        filename = mypath.split('/')[-1]\n",
        "        shutil.move(mypath , valid_dir + filename)\n",
        "    else:\n",
        "        print(f'{mypath} not found')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Directory /content/valid/ is created successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwIopbOnyPSG"
      },
      "source": [
        "!mv train_data_raw train "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lPUtkozQWM2"
      },
      "source": [
        "Directories fixup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukBQq468yXcW"
      },
      "source": [
        "def lookup_image_file_paths(formats, dir):\n",
        "    \"\"\"\n",
        "    This function takes a specified set of formats and directory address to list all the filepaths\n",
        "    of the desired format in that directory\n",
        "    \"\"\"\n",
        "    filepaths = []\n",
        "    for format in formats:\n",
        "        filepaths.extend(glob.glob(f'{dir}*.{format}'))\n",
        "    return filepaths\n",
        "\n",
        "def make_txt_file(formats, dir):\n",
        "    \"\"\"\n",
        "    Formats the file names to write in the desired txt file\n",
        "    \"\"\"\n",
        "    filepaths = lookup_image_file_paths(formats, dir)\n",
        "    \n",
        "    filenames = [x.split('/')[-1] for x in filepaths]\n",
        "    txt_file_name = dir.split('/')[-2]\n",
        "\n",
        "    print(f'{txt_file_name} : {len(filepaths)} images')\n",
        "    with open(f'/content/metadata/{txt_file_name}.txt', 'w') as outfile:\n",
        "        for filename in filenames:\n",
        "            outfile.write(f'data/{txt_file_name}/'+filename+'\\n')\n",
        "        outfile.close()\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1pEEMYxyY6H",
        "outputId": "3c3d23bd-b8c7-43e3-b82d-228fcd439b42"
      },
      "source": [
        "train_dir = '/content/train/'\n",
        "valid_dir = '/content/valid/'\n",
        "!mkdir metadata\n",
        "\n",
        "# Making the .txt file containing list of images. \n",
        "make_txt_file(formats, dir = train_dir)\n",
        "make_txt_file(formats, dir = valid_dir)\n",
        "\n",
        "# Writing the file traffic.names\n",
        "object_labels = list(lut.keys())\n",
        "with open('/content/metadata/trash.names', 'w') as outfile:\n",
        "    for label in object_labels:\n",
        "        outfile.write(label + '\\n')\n",
        "    outfile.close()\n",
        "\n",
        "# Writing the file traffic.data\n",
        "data_config = f'classes=4\\ntrain=train.txt\\nvalid=valid.txt\\nnames=traffic.names'\n",
        "with open('/content/metadata/trash.data', 'w') as outfile:\n",
        "    outfile.write(data_config + '\\n')\n",
        "    outfile.close()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train : 300 images\n",
            "valid : 69 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUM6COKDyhCs"
      },
      "source": [
        "!zip -r trash-processed.zip train valid metadata\n",
        "clear_output()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EcmIs4XQatN"
      },
      "source": [
        "Uploading processed zip to drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBvjtU5MPPLH",
        "outputId": "4daa1c7f-9fa2-47b6-b9d9-f1e2943eff70"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoEcOTmLyldm"
      },
      "source": [
        "!cp trash-processed.zip '/content/drive/MyDrive/Plastic Detection'"
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}